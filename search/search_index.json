{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Helloo \u00b6 What is this? \u00b6 This is basically my unix and everything techy knowledge base. I made this to help lessen the blow on my retarded memory retention abilities. This is hosted on Github Pages and is built using MkDocs with a customized theme based off of the superb Material theme. If you're viewing this and feel like I've made a mistake. Please click that repo icon and shoot me a pull request. I'd appreciate any help. Sites \u00b6 Stuff I've sprung up over the course of my learning endeavors. AniTracker One of the best things that happened to me during the pandemic was the boredom that came with staying at home all day. This made me explore a ton of new different technologies. One of them was the js library react. This is the new and improved anime tracker v2. Built using React and hosted on Netlify. The site uses the Anilist GQL api to grab data and does it so using the Apollo Client. Visit it here Find the code here Birthday Tracker When it comes to remembering birthdays, I suck at it. That's what inspired me to build this. Hosted on Netlify all the data it uses is saved in a nice AES encrypted package within the site's root directory. Even then, without a rightful backend notifications are impossible so this is what I'd consider a half baked solution. Visit it here Find the code here Mythicon - Demo Made this for a competition a while back. Even though I wasn't able to grab a position within the top three with this. I'm still proud of the design. Visit it here Find the code here Old Anime Tracker The vanilla js, html and scss based predecessor to the current Anime Tracker. This was the result of me trying to put my love for anime together with my enthusiasm for API based site architectures. This is based on Anilist, a site I'm a very big fan of. From it's designs to it's wonderful color scheme. Which in essence is what inspired this docs' color scheme as well. So basically, the team behind Anilist made a pretty wonderful GQL based API to access their site data. And me, wanting to try my hand with some AJAX using JS, used that opportunity to make this thing. It's simply a stripped down anime viewer. Visit it here Find the code here Desktop \u00b6 Dot files for my Manjaro rice. August 2020 Find the dots here","title":"Home"},{"location":"#helloo","text":"","title":"Helloo"},{"location":"#what-is-this","text":"This is basically my unix and everything techy knowledge base. I made this to help lessen the blow on my retarded memory retention abilities. This is hosted on Github Pages and is built using MkDocs with a customized theme based off of the superb Material theme. If you're viewing this and feel like I've made a mistake. Please click that repo icon and shoot me a pull request. I'd appreciate any help.","title":"What is this?"},{"location":"#sites","text":"Stuff I've sprung up over the course of my learning endeavors. AniTracker One of the best things that happened to me during the pandemic was the boredom that came with staying at home all day. This made me explore a ton of new different technologies. One of them was the js library react. This is the new and improved anime tracker v2. Built using React and hosted on Netlify. The site uses the Anilist GQL api to grab data and does it so using the Apollo Client. Visit it here Find the code here Birthday Tracker When it comes to remembering birthdays, I suck at it. That's what inspired me to build this. Hosted on Netlify all the data it uses is saved in a nice AES encrypted package within the site's root directory. Even then, without a rightful backend notifications are impossible so this is what I'd consider a half baked solution. Visit it here Find the code here Mythicon - Demo Made this for a competition a while back. Even though I wasn't able to grab a position within the top three with this. I'm still proud of the design. Visit it here Find the code here Old Anime Tracker The vanilla js, html and scss based predecessor to the current Anime Tracker. This was the result of me trying to put my love for anime together with my enthusiasm for API based site architectures. This is based on Anilist, a site I'm a very big fan of. From it's designs to it's wonderful color scheme. Which in essence is what inspired this docs' color scheme as well. So basically, the team behind Anilist made a pretty wonderful GQL based API to access their site data. And me, wanting to try my hand with some AJAX using JS, used that opportunity to make this thing. It's simply a stripped down anime viewer. Visit it here Find the code here","title":"Sites"},{"location":"#desktop","text":"Dot files for my Manjaro rice. August 2020 Find the dots here","title":"Desktop"},{"location":"pages/apache/","text":"Setup \u00b6 Install apache2 and the php plugins. Make sure that phpx.x-fpm is already installed. Because we're using fpm the original phpx.x package is not needed. libapache2-mod-fcgid enables apache to run the php server with FPM. sudo apt install apache2 libapache2-mod-fcgid For apache to handle php you need to edit the /etc/apache2/mods-enabled/dir.conf . And replace it's <IfModule> with this. <IfModule mod_dir.c > DirectoryIndex index.html index.cgi index.pl index.php index.xhtml index.htm </IfModule> Now enable the apache php module and FastCGI config module. sudo a2enmod actions fcgid alias proxy_fcgi setenvif sudo a2enconf phpx.x-fpm # don't forget sudo service apache2 restart Make sure to add this line to all site configs for php scripting support. <FilesMatch \\.php$ > SetHandler \"proxy:unix:/var/run/php/phpx.x-fpm.sock|fcgi://localhost\" </FilesMatch> Config \u00b6 Config example for site with .htaccess files. <VirtualHost *:80 > ServerAdmin webmaster@example.com ServerName example.com DocumentRoot /var/www/loc <Directory /var/www/loc > Options Indexes FollowSymLinks MultiViews AllowOverride All Require all granted allow from all LimitRequestBody 5242880 </Directory> <FilesMatch \\.php$ > SetHandler \"proxy:unix:/var/run/php/phpx.x-fpm.sock|fcgi://localhost\" </FilesMatch> </VirtualHost> Behind Nginx \u00b6 To run both Apache and Nginx at the same time, you need to expose one to the net and run the other through a proxy. First there's Nginx which listens to port 80. It acts as the gateway to both Nginx native requests and Apache requests. Apache on the other hand is listening on a different port. Any request going towards Apache will be forwarded to it's port by an Nginx config which will then be picked up by it's corresponding resolver on Apache's side. Steps \u00b6 Check PHP versions Install Apache Setup Apache Change Apache port Configure Nginx proxy Check if all's well Check Apache installation, PHP installation, PHP version and if all the related modules exist and are enabled 1 . Then add the apache modules to run php FPM 2 . Configure Apache to listen to the different port. It may be any port you wish. Just make sure to never open this port to the internet. This can be done by changing the listening port at /etc/apache2/ports.conf . Listen 8080 The port should be mentioned in the virtual host of every site config at /etc/apache2/sites-enabled as well. <VirtualHost *:8080 > # config </VirtualHost> As for the proxy. An Nginx site config is needed with the following content. server { listen 80 ; server_name <apache.domain> ; location / { proxy_pass http://<server_ip>:8080 ; proxy_set_header Host $host ; proxy_set_header X-Real-IP $remote_addr ; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for ; proxy_set_header X-Forwarded-Proto $scheme ; } } Finally check if everything works fine by popping up a php test file. More info here . Check the Server API field to see if FastCGI is active. Build Date - Server API FPM/FastCGI Virtual.. - https://www.digitalocean.com/community/tutorials/how-to-configure-nginx-as-a-web-server-and-reverse-proxy-for-apache-on-one-ubuntu-20-04-server \u21a9 https://tecadmin.net/setup-apache-php-fpm-ubuntu-20-04/ \u21a9","title":"Apache"},{"location":"pages/apache/#setup","text":"Install apache2 and the php plugins. Make sure that phpx.x-fpm is already installed. Because we're using fpm the original phpx.x package is not needed. libapache2-mod-fcgid enables apache to run the php server with FPM. sudo apt install apache2 libapache2-mod-fcgid For apache to handle php you need to edit the /etc/apache2/mods-enabled/dir.conf . And replace it's <IfModule> with this. <IfModule mod_dir.c > DirectoryIndex index.html index.cgi index.pl index.php index.xhtml index.htm </IfModule> Now enable the apache php module and FastCGI config module. sudo a2enmod actions fcgid alias proxy_fcgi setenvif sudo a2enconf phpx.x-fpm # don't forget sudo service apache2 restart Make sure to add this line to all site configs for php scripting support. <FilesMatch \\.php$ > SetHandler \"proxy:unix:/var/run/php/phpx.x-fpm.sock|fcgi://localhost\" </FilesMatch>","title":"Setup"},{"location":"pages/apache/#config","text":"Config example for site with .htaccess files. <VirtualHost *:80 > ServerAdmin webmaster@example.com ServerName example.com DocumentRoot /var/www/loc <Directory /var/www/loc > Options Indexes FollowSymLinks MultiViews AllowOverride All Require all granted allow from all LimitRequestBody 5242880 </Directory> <FilesMatch \\.php$ > SetHandler \"proxy:unix:/var/run/php/phpx.x-fpm.sock|fcgi://localhost\" </FilesMatch> </VirtualHost>","title":"Config"},{"location":"pages/apache/#behind-nginx","text":"To run both Apache and Nginx at the same time, you need to expose one to the net and run the other through a proxy. First there's Nginx which listens to port 80. It acts as the gateway to both Nginx native requests and Apache requests. Apache on the other hand is listening on a different port. Any request going towards Apache will be forwarded to it's port by an Nginx config which will then be picked up by it's corresponding resolver on Apache's side.","title":"Behind Nginx"},{"location":"pages/apache/#steps","text":"Check PHP versions Install Apache Setup Apache Change Apache port Configure Nginx proxy Check if all's well Check Apache installation, PHP installation, PHP version and if all the related modules exist and are enabled 1 . Then add the apache modules to run php FPM 2 . Configure Apache to listen to the different port. It may be any port you wish. Just make sure to never open this port to the internet. This can be done by changing the listening port at /etc/apache2/ports.conf . Listen 8080 The port should be mentioned in the virtual host of every site config at /etc/apache2/sites-enabled as well. <VirtualHost *:8080 > # config </VirtualHost> As for the proxy. An Nginx site config is needed with the following content. server { listen 80 ; server_name <apache.domain> ; location / { proxy_pass http://<server_ip>:8080 ; proxy_set_header Host $host ; proxy_set_header X-Real-IP $remote_addr ; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for ; proxy_set_header X-Forwarded-Proto $scheme ; } } Finally check if everything works fine by popping up a php test file. More info here . Check the Server API field to see if FastCGI is active. Build Date - Server API FPM/FastCGI Virtual.. - https://www.digitalocean.com/community/tutorials/how-to-configure-nginx-as-a-web-server-and-reverse-proxy-for-apache-on-one-ubuntu-20-04-server \u21a9 https://tecadmin.net/setup-apache-php-fpm-ubuntu-20-04/ \u21a9","title":"Steps"},{"location":"pages/database/","text":"Setup \u00b6 Install MariaDB and run the initial setup script 1 sudo apt update sudo apt install mariadb-server sudo mysql_secure_installation Usual Process \u00b6 Create db and give the <username> user access to the <db-name> db 1 . -- create db CREATE DATABASE < db - name > ; -- create user CREATE USER '<username>' @ localhost IDENTIFIED BY '<password>' ; -- grant privileges GRANT ALL PRIVILEGES ON < db - name > . * TO '<username>' @ localhost ; -- save grant changes FLUSH PRIVILEGES ; Useful Commands \u00b6 Deleting \u00b6 -- drop user DROP USER '<user-name>' @ localhost ; -- drop database DROP DATABASE < db - name > Checking \u00b6 -- display users SELECT User FROM mysql . user ; -- display privileges SHOW GRANTS FOR '<username>' @ localhost ; -- display databases SHOW DATABASES ; -- display columns of table DESC db . table ; SHOW COLUMNS FROM db . table ; Displaying \u00b6 -- display vertically SHOW DATABASES \\ G ; SELECT col FROM db \\ G ; https://www.digitalocean.com/community/tutorials/how-to-install-mariadb-on-ubuntu-20-04 \u21a9 \u21a9","title":"Databases"},{"location":"pages/database/#setup","text":"Install MariaDB and run the initial setup script 1 sudo apt update sudo apt install mariadb-server sudo mysql_secure_installation","title":"Setup"},{"location":"pages/database/#usual-process","text":"Create db and give the <username> user access to the <db-name> db 1 . -- create db CREATE DATABASE < db - name > ; -- create user CREATE USER '<username>' @ localhost IDENTIFIED BY '<password>' ; -- grant privileges GRANT ALL PRIVILEGES ON < db - name > . * TO '<username>' @ localhost ; -- save grant changes FLUSH PRIVILEGES ;","title":"Usual Process"},{"location":"pages/database/#useful-commands","text":"","title":"Useful Commands"},{"location":"pages/database/#deleting","text":"-- drop user DROP USER '<user-name>' @ localhost ; -- drop database DROP DATABASE < db - name >","title":"Deleting"},{"location":"pages/database/#checking","text":"-- display users SELECT User FROM mysql . user ; -- display privileges SHOW GRANTS FOR '<username>' @ localhost ; -- display databases SHOW DATABASES ; -- display columns of table DESC db . table ; SHOW COLUMNS FROM db . table ;","title":"Checking"},{"location":"pages/database/#displaying","text":"-- display vertically SHOW DATABASES \\ G ; SELECT col FROM db \\ G ; https://www.digitalocean.com/community/tutorials/how-to-install-mariadb-on-ubuntu-20-04 \u21a9 \u21a9","title":"Displaying"},{"location":"pages/duckduckgo/","text":"Theme from URL \u00b6 First format the bookmarklet url into the format the script accepts. To do that replace the & with ; and get rid of the k that every parameter starts with. For example; https://duckduckgo.com/?kae=d&ks=m&kak=-1&kax=-1&kaq=-1&kap=-1&kao=-1&kau=-1&k5=1&k7=1a1b26&kj=16161e&kx=1abc9c&k21=16161E&k18=-1&ka=e&kaa=BB9AF7&k9=C0CAF5&k8=6183BB&kt=e Would be; ae=d; s=m; ak=-1; ax=-1; aq=-1; ap=-1; ao=-1; au=-1; 5=1; 7=1a1b26; j=16161e; x=1abc9c; 21=16161E; 18=-1; a=e; aa=BB9AF7; 9=C0CAF5; 8=6183BB; t=e Then just run this script replacing ddg_cookie_input with the formatted url. You must run it using the browser console from https://duckduckgo.com . // Converts DDG cookie string into formatted JSON const makeCookieData = ( ddg_cookie_input ) => { let ddg_json = {}; const items = ddg_cookie_input . split ( /[ ,]+/ ); items . forEach (( item )=>{ let parts = item . split ( '=' ); ddg_json [ parts [ 0 ]] = parts [ 1 ]; }); return ddg_json ; } // Iterates over JSON, and adds to browser cookie store const setCookies = ( ddg_json ) => { Object . keys ( ddg_json ). forEach ( function ( key ) { document . cookie = ` ${ key } = ${ ddg_json [ key ] } ` ; }); } // Paste your cookie data here const ddg_cookie_input = `5=1; ay=b; bc=1; ae=d; ax=v261-7; 18=1; aa=0a7355; x=a8d3ff; 8=d3d5e5; 9=00af87; j=080813; 7=0b1021; 21=080813; a=Hack; t=v` ; // Call set cookies, passing in formatted cookie data setCookies ( makeCookieData ( ddg_cookie_input )); // All done, reload page for changes to take effect :) location . reload ();","title":"DuckDuckGo"},{"location":"pages/duckduckgo/#theme-from-url","text":"First format the bookmarklet url into the format the script accepts. To do that replace the & with ; and get rid of the k that every parameter starts with. For example; https://duckduckgo.com/?kae=d&ks=m&kak=-1&kax=-1&kaq=-1&kap=-1&kao=-1&kau=-1&k5=1&k7=1a1b26&kj=16161e&kx=1abc9c&k21=16161E&k18=-1&ka=e&kaa=BB9AF7&k9=C0CAF5&k8=6183BB&kt=e Would be; ae=d; s=m; ak=-1; ax=-1; aq=-1; ap=-1; ao=-1; au=-1; 5=1; 7=1a1b26; j=16161e; x=1abc9c; 21=16161E; 18=-1; a=e; aa=BB9AF7; 9=C0CAF5; 8=6183BB; t=e Then just run this script replacing ddg_cookie_input with the formatted url. You must run it using the browser console from https://duckduckgo.com . // Converts DDG cookie string into formatted JSON const makeCookieData = ( ddg_cookie_input ) => { let ddg_json = {}; const items = ddg_cookie_input . split ( /[ ,]+/ ); items . forEach (( item )=>{ let parts = item . split ( '=' ); ddg_json [ parts [ 0 ]] = parts [ 1 ]; }); return ddg_json ; } // Iterates over JSON, and adds to browser cookie store const setCookies = ( ddg_json ) => { Object . keys ( ddg_json ). forEach ( function ( key ) { document . cookie = ` ${ key } = ${ ddg_json [ key ] } ` ; }); } // Paste your cookie data here const ddg_cookie_input = `5=1; ay=b; bc=1; ae=d; ax=v261-7; 18=1; aa=0a7355; x=a8d3ff; 8=d3d5e5; 9=00af87; j=080813; 7=0b1021; 21=080813; a=Hack; t=v` ; // Call set cookies, passing in formatted cookie data setCookies ( makeCookieData ( ddg_cookie_input )); // All done, reload page for changes to take effect :) location . reload ();","title":"Theme from URL"},{"location":"pages/fail2ban/","text":"Commands \u00b6 # fail2ban server status sudo service fail2ban status # see jail status sudo fail2ban-client status ssh # manually ban ip sudo fail2ban-client set sshd banip 23 .34.45.56 # manually unban ip sudo fail2ban-client set sshd unbanip 23 .34.45.56 Installation \u00b6 Setup a Mail Transfer Agent, for example postfix . Then install fail2ban . Make sure to stop its automatically started service. sudo apt install fail2ban sudo service fail2ban stop Configuration \u00b6 Fail2ban reads files from two configuration formats. Files that end with the suffixes .conf (original) and .local (custom) within /etc/fail2ban . The default config files of fail2ban come saved with the suffix .conf . Never touch these files. There's a possibility of them being overwritten after package updates. Always make changes after creating a copy of the with the .local suffix. The .local files don't have to include all settings from the corresponding .conf file, only those that need to be overridden. The configs below are meant to be self sufficient. Meaning the files don't need extra rules other than the ones stated to function as intended. fail2ban.conf = > fail2ban.local jail.conf = > jail.local action.d/mail-whois.conf = > mail-whois.local jail.d/defaults-debian.conf = > defaults-debian.local defaults-debian.local \u00b6 Prevent ufw conflicts. [sshd] enabled = false fail2ban.local \u00b6 Change log level. [DEFAULT] loglevel = INFO jail.local \u00b6 Setup the main jail which fail2ban would be listening to and blocking ips. [ssh] enabled = true port = <ssh-port> filter = sshd logpath = /var/log/auth.log maxretry = 4 bantime = 1w findtime = 1d destemail = <dest-email> sender = fail2ban mta = mail chain = <known/chain> # basically what happens when blocking action_mwl = ufw[application=\"OpenSSH\", blocktype=reject] %(mta)s-whois[name = %(__name__)s, sender=\"%(sender)s\", dest=\"%(destemail)s\", protocol=\"%(protocol)s\", chain=\"%(chain)s\"] action = %(action_mwl)s mail-whois.local \u00b6 To configure the mail templates. [INCLUDES] before = mail-whois-common.conf [Definition] norestored = 1 actionstart = printf %%b \"Hi,\\n The jail <name> has been started successfully.\\n Regards,\\n Fail2Ban\"|mail -s \"Code Green: Fail2Ban Started\" <dest> actionstop = printf %%b \"Hi,\\n The jail <name> has been stopped.\\n Regards,\\n Fail2Ban\"|mail -s \"Code Red: Fail2Ban Stopped\" <dest> actionban = printf %%b \"Hi,\\n The IP <ip> has just been banned by Fail2Ban after <failures> attempts against <name>.\\n\\n Here is more information about <ip> :\\n `%(_whois_command)s`\\n Regards,\\n Fail2Ban\"|mail -s \"Code Yellow: SSH banned ip\" <dest> [Init] name = default # addressee of the mail dest = fail2ban Troubleshooting \u00b6 When encountering potential ufw conflicts resulting in already banned errors. Check 1 . Also check out ufw's OpenSSH app. Cos that's the reference fail2ban uses to ban stuff 2 . https://askubuntu.com/questions/54771/potential-ufw-and-fail2ban-conflicts \u21a9 https://www.fail2ban.org/wiki/index.php/FAQ_english \u21a9","title":"Fail2Ban"},{"location":"pages/fail2ban/#commands","text":"# fail2ban server status sudo service fail2ban status # see jail status sudo fail2ban-client status ssh # manually ban ip sudo fail2ban-client set sshd banip 23 .34.45.56 # manually unban ip sudo fail2ban-client set sshd unbanip 23 .34.45.56","title":"Commands"},{"location":"pages/fail2ban/#installation","text":"Setup a Mail Transfer Agent, for example postfix . Then install fail2ban . Make sure to stop its automatically started service. sudo apt install fail2ban sudo service fail2ban stop","title":"Installation"},{"location":"pages/fail2ban/#configuration","text":"Fail2ban reads files from two configuration formats. Files that end with the suffixes .conf (original) and .local (custom) within /etc/fail2ban . The default config files of fail2ban come saved with the suffix .conf . Never touch these files. There's a possibility of them being overwritten after package updates. Always make changes after creating a copy of the with the .local suffix. The .local files don't have to include all settings from the corresponding .conf file, only those that need to be overridden. The configs below are meant to be self sufficient. Meaning the files don't need extra rules other than the ones stated to function as intended. fail2ban.conf = > fail2ban.local jail.conf = > jail.local action.d/mail-whois.conf = > mail-whois.local jail.d/defaults-debian.conf = > defaults-debian.local","title":"Configuration"},{"location":"pages/fail2ban/#defaults-debianlocal","text":"Prevent ufw conflicts. [sshd] enabled = false","title":"defaults-debian.local"},{"location":"pages/fail2ban/#fail2banlocal","text":"Change log level. [DEFAULT] loglevel = INFO","title":"fail2ban.local"},{"location":"pages/fail2ban/#jaillocal","text":"Setup the main jail which fail2ban would be listening to and blocking ips. [ssh] enabled = true port = <ssh-port> filter = sshd logpath = /var/log/auth.log maxretry = 4 bantime = 1w findtime = 1d destemail = <dest-email> sender = fail2ban mta = mail chain = <known/chain> # basically what happens when blocking action_mwl = ufw[application=\"OpenSSH\", blocktype=reject] %(mta)s-whois[name = %(__name__)s, sender=\"%(sender)s\", dest=\"%(destemail)s\", protocol=\"%(protocol)s\", chain=\"%(chain)s\"] action = %(action_mwl)s","title":"jail.local"},{"location":"pages/fail2ban/#mail-whoislocal","text":"To configure the mail templates. [INCLUDES] before = mail-whois-common.conf [Definition] norestored = 1 actionstart = printf %%b \"Hi,\\n The jail <name> has been started successfully.\\n Regards,\\n Fail2Ban\"|mail -s \"Code Green: Fail2Ban Started\" <dest> actionstop = printf %%b \"Hi,\\n The jail <name> has been stopped.\\n Regards,\\n Fail2Ban\"|mail -s \"Code Red: Fail2Ban Stopped\" <dest> actionban = printf %%b \"Hi,\\n The IP <ip> has just been banned by Fail2Ban after <failures> attempts against <name>.\\n\\n Here is more information about <ip> :\\n `%(_whois_command)s`\\n Regards,\\n Fail2Ban\"|mail -s \"Code Yellow: SSH banned ip\" <dest> [Init] name = default # addressee of the mail dest = fail2ban","title":"mail-whois.local"},{"location":"pages/fail2ban/#troubleshooting","text":"When encountering potential ufw conflicts resulting in already banned errors. Check 1 . Also check out ufw's OpenSSH app. Cos that's the reference fail2ban uses to ban stuff 2 . https://askubuntu.com/questions/54771/potential-ufw-and-fail2ban-conflicts \u21a9 https://www.fail2ban.org/wiki/index.php/FAQ_english \u21a9","title":"Troubleshooting"},{"location":"pages/flask/","text":"No Cache \u00b6 Flask by default caches files on client devices. When in development, this is a goddamn headache. Especially when you're writing CSS. Unlike VSCode's live reload , syncing stylesheet and script changes in a flask app requires you to fully reload a page. This is done by a hard reload using Ctrl + F5 . The code below counters this by specifying in the response header telling clients not to save anything. # don't fucking save assets in cache @app . after_request def add_header ( r ): r . headers [ \"Cache-Control\" ] = \"no-cache, no-store, must-revalidate\" r . headers [ \"Pragma\" ] = \"no-cache\" r . headers [ \"Expires\" ] = \"0\" r . headers [ \"Cache-Control\" ] = \"public, max-age=0\" return r Deployment \u00b6 Setup database Create systemd service for gunicorn Create hook instance config json Configure GitHub repo's webhook settings Create a group for the hook service Create a systemd service for the hook instance Write the pull and reload script Connecting a DB \u00b6 First create a separate database and user for the web-app in the usual way . Then reference the db from the flask app. To get MariaDB working on SQLAlchemy you'll also need to install the pymysql package 2 . app . config [ 'SQLALCHEMY_DATABASE_URI' ] = \"mysql+pymysql://<username>:<password>@localhost/<app-db-name>?charset=utf8mb4\" Gunicorn Service \u00b6 To run a flask app in development you need a WSGI HTTP Server to serve and run it. This is where gunicorn comes in. Development \u00b6 When in development you can run gunicorn in the shell. The <app-name> refers to the file name of the flask app and the app refers to the name of the callable within it. # run it on port 5000 gunicorn --bind localhost:5000 <app-name>:app Production \u00b6 When deploying, create a systemd service for the gunicorn . See more info about creating systemd services here . Find info about workers and optimizations here . Here's an example systemd config for gunicorn. [Unit] Description = Gunicorn instance serving the app After = network.target [Service] User = <reg_user> Group = www-data WorkingDirectory = /home/<reg_user>/project ExecStart = /usr/local/bin/gunicorn --workers 3 --bind localhost:5000 <app-name>:app [Install] WantedBy = multi-user.target Hook Instance \u00b6 Create a webhook instance json file and connect it with Github to listen to push requests from the repo. More info here . Then create a new group for the flask app and couple it with the already existing webhook user created when setting up the webhook application. In it whitelist the systemctl commands for dealing with the gunicorn service. Write a systemd service file with the webhook user and the new group for the hook instance. Find out how here . Integration Script \u00b6 Since systemd runs services in isolated environments. Without access to the user shell nor any environment variables. So, for private repos an ssh-agent needs to be started every time the script is run for Github authentication. More info here . First clean the repo of any untracked changes. Then pull the latest commit. Find how here . Finally reload the site. Make sure to only use the systemctl commands that were defined in the group the hook instance is running on. systemctl restart <app-service> https://phoenixnap.com/kb/how-to-create-mariadb-user-grant-privileges \u21a9 https://stackoverflow.com/questions/54834088/python-database-connection-for-mariadb-using-sqlalchemy \u21a9","title":"Flask"},{"location":"pages/flask/#no-cache","text":"Flask by default caches files on client devices. When in development, this is a goddamn headache. Especially when you're writing CSS. Unlike VSCode's live reload , syncing stylesheet and script changes in a flask app requires you to fully reload a page. This is done by a hard reload using Ctrl + F5 . The code below counters this by specifying in the response header telling clients not to save anything. # don't fucking save assets in cache @app . after_request def add_header ( r ): r . headers [ \"Cache-Control\" ] = \"no-cache, no-store, must-revalidate\" r . headers [ \"Pragma\" ] = \"no-cache\" r . headers [ \"Expires\" ] = \"0\" r . headers [ \"Cache-Control\" ] = \"public, max-age=0\" return r","title":"No Cache"},{"location":"pages/flask/#deployment","text":"Setup database Create systemd service for gunicorn Create hook instance config json Configure GitHub repo's webhook settings Create a group for the hook service Create a systemd service for the hook instance Write the pull and reload script","title":"Deployment"},{"location":"pages/flask/#connecting-a-db","text":"First create a separate database and user for the web-app in the usual way . Then reference the db from the flask app. To get MariaDB working on SQLAlchemy you'll also need to install the pymysql package 2 . app . config [ 'SQLALCHEMY_DATABASE_URI' ] = \"mysql+pymysql://<username>:<password>@localhost/<app-db-name>?charset=utf8mb4\"","title":"Connecting a DB"},{"location":"pages/flask/#gunicorn-service","text":"To run a flask app in development you need a WSGI HTTP Server to serve and run it. This is where gunicorn comes in.","title":"Gunicorn Service"},{"location":"pages/flask/#development","text":"When in development you can run gunicorn in the shell. The <app-name> refers to the file name of the flask app and the app refers to the name of the callable within it. # run it on port 5000 gunicorn --bind localhost:5000 <app-name>:app","title":"Development"},{"location":"pages/flask/#production","text":"When deploying, create a systemd service for the gunicorn . See more info about creating systemd services here . Find info about workers and optimizations here . Here's an example systemd config for gunicorn. [Unit] Description = Gunicorn instance serving the app After = network.target [Service] User = <reg_user> Group = www-data WorkingDirectory = /home/<reg_user>/project ExecStart = /usr/local/bin/gunicorn --workers 3 --bind localhost:5000 <app-name>:app [Install] WantedBy = multi-user.target","title":"Production"},{"location":"pages/flask/#hook-instance","text":"Create a webhook instance json file and connect it with Github to listen to push requests from the repo. More info here . Then create a new group for the flask app and couple it with the already existing webhook user created when setting up the webhook application. In it whitelist the systemctl commands for dealing with the gunicorn service. Write a systemd service file with the webhook user and the new group for the hook instance. Find out how here .","title":"Hook Instance"},{"location":"pages/flask/#integration-script","text":"Since systemd runs services in isolated environments. Without access to the user shell nor any environment variables. So, for private repos an ssh-agent needs to be started every time the script is run for Github authentication. More info here . First clean the repo of any untracked changes. Then pull the latest commit. Find how here . Finally reload the site. Make sure to only use the systemctl commands that were defined in the group the hook instance is running on. systemctl restart <app-service> https://phoenixnap.com/kb/how-to-create-mariadb-user-grant-privileges \u21a9 https://stackoverflow.com/questions/54834088/python-database-connection-for-mariadb-using-sqlalchemy \u21a9","title":"Integration Script"},{"location":"pages/gcontacts/","text":"Importable csv \u00b6 Batch convert plain csv file with mobile numbers to google contacts importable csv. This also removes duplicates. import csv numlist = [] with open ( 'math.csv' , mode = 'r' ) as file : csv_reader = csv . DictReader ( file ) for row in csv_reader : numlist . append ( row [ 'first' ]) filtred = set ( numlist ) formatted = {} for x , num in enumerate ( filtred ): item = x % 256 base = x // 256 formatted [ f 'CM { base : 02d } - { item : 03d } ' ] = num with open ( 'new_math.csv' , mode = 'w' ) as file : fieldnames = [ 'Name' , 'Given Name' , 'Additional Name' , 'Family Name' , 'Yomi Name' , 'Given Name Yomi' , 'Additional Name Yomi' , 'Family Name Yomi' , 'Name Prefix' , 'Name Suffix' , 'Initials' , 'Nickname' , 'Short Name' , 'Maiden Name' , 'Birthday' , 'Gender' , 'Location' , 'Billing Information' , 'Directory Server' , 'Mileage' , 'Occupation' , 'Hobby' , 'Sensitivity' , 'Priority' , 'Subject' , 'Notes' , 'Language' , 'Photo' , 'Group Membership' , 'Phone 1 - Type' , 'Phone 1 - Value' ] writer = csv . DictWriter ( file , fieldnames = fieldnames ) writer . writeheader () for x , y in formatted . items (): writer . writerow ({ 'Phone 1 - Value' : y , 'Name' : x })","title":"GContacts"},{"location":"pages/gcontacts/#importable-csv","text":"Batch convert plain csv file with mobile numbers to google contacts importable csv. This also removes duplicates. import csv numlist = [] with open ( 'math.csv' , mode = 'r' ) as file : csv_reader = csv . DictReader ( file ) for row in csv_reader : numlist . append ( row [ 'first' ]) filtred = set ( numlist ) formatted = {} for x , num in enumerate ( filtred ): item = x % 256 base = x // 256 formatted [ f 'CM { base : 02d } - { item : 03d } ' ] = num with open ( 'new_math.csv' , mode = 'w' ) as file : fieldnames = [ 'Name' , 'Given Name' , 'Additional Name' , 'Family Name' , 'Yomi Name' , 'Given Name Yomi' , 'Additional Name Yomi' , 'Family Name Yomi' , 'Name Prefix' , 'Name Suffix' , 'Initials' , 'Nickname' , 'Short Name' , 'Maiden Name' , 'Birthday' , 'Gender' , 'Location' , 'Billing Information' , 'Directory Server' , 'Mileage' , 'Occupation' , 'Hobby' , 'Sensitivity' , 'Priority' , 'Subject' , 'Notes' , 'Language' , 'Photo' , 'Group Membership' , 'Phone 1 - Type' , 'Phone 1 - Value' ] writer = csv . DictWriter ( file , fieldnames = fieldnames ) writer . writeheader () for x , y in formatted . items (): writer . writerow ({ 'Phone 1 - Value' : y , 'Name' : x })","title":"Importable csv"},{"location":"pages/general/","text":"Commands \u00b6 # output linux version cat \"/proc/version\" # see last 10 logins who wtmp | tail -10 # connect to a docker container terminal docker exec -it <cont> bash # find a keyword from an output grep '<keyword(s)>' # strip and output only the selected column awk '{print $<col_num>}' # info about a pid ps -Flww -p <pid> Site Permissions \u00b6 Site permissions when popping up a new site. sudo chown -R www-data:www-data loc/ sudo chmod -R 774 loc/ Manual Fonts \u00b6 For a single user place fonts in 4 ; ~/.local/share/fonts For system-wide fonts place them in 4 ; /usr/local/share/fonts # don't touch this # it's only for pacman /usr/share/fonts/ Sudo \u00b6 One of the main things to do is to change the password asked when a user calls onto sudo. Making it ask for the root password is secure than the user pwd. So in the /etc/sudoers file; Defaults rootpw Add a user to sudoers usermod -a -G sudo <username> Whitelisting \u00b6 Whitelisting a command or set of commands for a group allows anyone who's in it to run them without sudo . This is done by creating a new file inside of /etc/sudoers.d 2 . sudo visudo -f \"/etc/sudoers.d/<file-name>\" Inside it the following properties whitelists the app 3 . Remember to give the abs path for the application. Use which <app-name> to find it. Cmnd_Alias <SET-NAME> = <abs-app-path> command, <apb-app-path> command %<group-name> ALL = (ALL) NOPASSWD: <SET-NAME> System User \u00b6 A user with no home directory, login shell nor password. It's basically a no-login dummy account made solely to containerize services. # create a system user and group of the same name sudo useradd --system --no-create-home --shell = /sbin/nologin <username> # set their permissions sudo chown -R root:<username> /path/to/change sudo chmod -R 775 /path/to/change chsh \u00b6 If you ever get the error; chsh : PAM authentication failed Find and comment this line inside etc/pam.d/chsh 1 . auth required pam_shells.so Then do whatever you were doing and make sure to uncomment it again . Groups \u00b6 List all groups getent group Add user to a group usermod -a -G group <username> What groups is a user in. If there's no args, groups of current user are shown. groups <user> Create new group groupadd <group> Make sure to restart the services that are responsible for the groups after adding a user into one. Necessary groups for reg user; docker sudo postfix GPG \u00b6 Decrypt a file. gpg --output <output-file> --decrypt <file.gpg> Encrypt a file. gpg --output <output-file.gpg> --encrypt <file> Export public and private keys. # public key gpg --output <public.pgp> --armor --export -r <recipient> # private key gpg --output <private.pgp> --armor --export-secret-key -r <recipient> https://ubuntuforums.org/showthread.php?t=1702833 \u21a9 https://askubuntu.com/questions/930768/adding-local-content-in-etc-sudoers-d-instead-of-directly-modifying-sodoers-fi \u21a9 https://askubuntu.com/questions/692701/allowing-user-to-run-systemctl-systemd-services-without-password \u21a9 https://wiki.archlinux.org/title/Fonts#Manual_installation \u21a9 \u21a9","title":"General"},{"location":"pages/general/#commands","text":"# output linux version cat \"/proc/version\" # see last 10 logins who wtmp | tail -10 # connect to a docker container terminal docker exec -it <cont> bash # find a keyword from an output grep '<keyword(s)>' # strip and output only the selected column awk '{print $<col_num>}' # info about a pid ps -Flww -p <pid>","title":"Commands"},{"location":"pages/general/#site-permissions","text":"Site permissions when popping up a new site. sudo chown -R www-data:www-data loc/ sudo chmod -R 774 loc/","title":"Site Permissions"},{"location":"pages/general/#manual-fonts","text":"For a single user place fonts in 4 ; ~/.local/share/fonts For system-wide fonts place them in 4 ; /usr/local/share/fonts # don't touch this # it's only for pacman /usr/share/fonts/","title":"Manual Fonts"},{"location":"pages/general/#sudo","text":"One of the main things to do is to change the password asked when a user calls onto sudo. Making it ask for the root password is secure than the user pwd. So in the /etc/sudoers file; Defaults rootpw Add a user to sudoers usermod -a -G sudo <username>","title":"Sudo"},{"location":"pages/general/#whitelisting","text":"Whitelisting a command or set of commands for a group allows anyone who's in it to run them without sudo . This is done by creating a new file inside of /etc/sudoers.d 2 . sudo visudo -f \"/etc/sudoers.d/<file-name>\" Inside it the following properties whitelists the app 3 . Remember to give the abs path for the application. Use which <app-name> to find it. Cmnd_Alias <SET-NAME> = <abs-app-path> command, <apb-app-path> command %<group-name> ALL = (ALL) NOPASSWD: <SET-NAME>","title":"Whitelisting"},{"location":"pages/general/#system-user","text":"A user with no home directory, login shell nor password. It's basically a no-login dummy account made solely to containerize services. # create a system user and group of the same name sudo useradd --system --no-create-home --shell = /sbin/nologin <username> # set their permissions sudo chown -R root:<username> /path/to/change sudo chmod -R 775 /path/to/change","title":"System User"},{"location":"pages/general/#chsh","text":"If you ever get the error; chsh : PAM authentication failed Find and comment this line inside etc/pam.d/chsh 1 . auth required pam_shells.so Then do whatever you were doing and make sure to uncomment it again .","title":"chsh"},{"location":"pages/general/#groups","text":"List all groups getent group Add user to a group usermod -a -G group <username> What groups is a user in. If there's no args, groups of current user are shown. groups <user> Create new group groupadd <group> Make sure to restart the services that are responsible for the groups after adding a user into one. Necessary groups for reg user; docker sudo postfix","title":"Groups"},{"location":"pages/general/#gpg","text":"Decrypt a file. gpg --output <output-file> --decrypt <file.gpg> Encrypt a file. gpg --output <output-file.gpg> --encrypt <file> Export public and private keys. # public key gpg --output <public.pgp> --armor --export -r <recipient> # private key gpg --output <private.pgp> --armor --export-secret-key -r <recipient> https://ubuntuforums.org/showthread.php?t=1702833 \u21a9 https://askubuntu.com/questions/930768/adding-local-content-in-etc-sudoers-d-instead-of-directly-modifying-sodoers-fi \u21a9 https://askubuntu.com/questions/692701/allowing-user-to-run-systemctl-systemd-services-without-password \u21a9 https://wiki.archlinux.org/title/Fonts#Manual_installation \u21a9 \u21a9","title":"GPG"},{"location":"pages/git/","text":"Local SSH \u00b6 To generate ssh keys, change key-name and /absolute/path ssh-keygen -t rsa -b 4096 -C \"key-name\" -f \"/absolute/path\" Check if ssh-agent is running eval \" $( ssh-agent -s ) \" Add generated ssh key to ssh-agent ssh-add \"/key/location\" Then just copy the .pub and paste it into github.com Rollback Changes \u00b6 This cleans up the repo of any untracked changes as per the last commit then pulls in the latest version. 1 . # clean up git reset git checkout . git clean -fdx # sync to latest git pull Automated Deployment \u00b6 There are multiple ways to automate deployment. See the pros and cons of each of these methods here . For more ways to do this check out this cheatsheet Deploy Keys \u00b6 This is very similar to local development with the usual ssh keys. The only difference is in how much this key gets to do. It's access is limited only to the repo it's added to. Create a key pair and add it here Repo > Settings > Deploy Keys ssh-keygen -t rsa -b 4096 -C \"key-name\" -f \"/abs/path\" Using deploy keys in scripts. The .ask-pass should echo the ssh key password. # start ssh-agent eval \" $( ssh-agent -s ) \" # add the ssh key DISPLAY = :0 SSH_ASKPASS = \"/abs/path/.ask-pass\" ssh-add ~/.ssh/<key-name> # do stuff # kill ssh-agent trap \"ssh-agent -k\" exit Always remember to kill what you start. https://stackoverflow.com/questions/14075581/git-undo-all-uncommitted-or-unsaved-changes \u21a9","title":"Git"},{"location":"pages/git/#local-ssh","text":"To generate ssh keys, change key-name and /absolute/path ssh-keygen -t rsa -b 4096 -C \"key-name\" -f \"/absolute/path\" Check if ssh-agent is running eval \" $( ssh-agent -s ) \" Add generated ssh key to ssh-agent ssh-add \"/key/location\" Then just copy the .pub and paste it into github.com","title":"Local SSH"},{"location":"pages/git/#rollback-changes","text":"This cleans up the repo of any untracked changes as per the last commit then pulls in the latest version. 1 . # clean up git reset git checkout . git clean -fdx # sync to latest git pull","title":"Rollback Changes"},{"location":"pages/git/#automated-deployment","text":"There are multiple ways to automate deployment. See the pros and cons of each of these methods here . For more ways to do this check out this cheatsheet","title":"Automated Deployment"},{"location":"pages/git/#deploy-keys","text":"This is very similar to local development with the usual ssh keys. The only difference is in how much this key gets to do. It's access is limited only to the repo it's added to. Create a key pair and add it here Repo > Settings > Deploy Keys ssh-keygen -t rsa -b 4096 -C \"key-name\" -f \"/abs/path\" Using deploy keys in scripts. The .ask-pass should echo the ssh key password. # start ssh-agent eval \" $( ssh-agent -s ) \" # add the ssh key DISPLAY = :0 SSH_ASKPASS = \"/abs/path/.ask-pass\" ssh-add ~/.ssh/<key-name> # do stuff # kill ssh-agent trap \"ssh-agent -k\" exit Always remember to kill what you start. https://stackoverflow.com/questions/14075581/git-undo-all-uncommitted-or-unsaved-changes \u21a9","title":"Deploy Keys"},{"location":"pages/javascript/","text":"Methods \u00b6 All of these achieve the same thing. const o = { fn : function () { // do something } } const o = { fn : () => { // do something } } const o = { fn () { // do something } } // run - do something o . fn","title":"Javascript"},{"location":"pages/javascript/#methods","text":"All of these achieve the same thing. const o = { fn : function () { // do something } } const o = { fn : () => { // do something } } const o = { fn () { // do something } } // run - do something o . fn","title":"Methods"},{"location":"pages/logwatch/","text":"Setup \u00b6 Instal logwatch apt-get install logwatch Go to config location micro \"/usr/share/logwatch/default.conf/\" Make a backup of the config file cp logwatch.conf backup.conf Edit the file according to the references https://www.digitalocean.com/community/tutorials/how-to-install-and-use-logwatch-log-analyzer-and-reporter-on-a-vps \u21a9 http://www.mewbies.com/how_to_install_and_configure_logwatch.html \u21a9","title":"Logwatch"},{"location":"pages/logwatch/#setup","text":"Instal logwatch apt-get install logwatch Go to config location micro \"/usr/share/logwatch/default.conf/\" Make a backup of the config file cp logwatch.conf backup.conf Edit the file according to the references https://www.digitalocean.com/community/tutorials/how-to-install-and-use-logwatch-log-analyzer-and-reporter-on-a-vps \u21a9 http://www.mewbies.com/how_to_install_and_configure_logwatch.html \u21a9","title":"Setup"},{"location":"pages/networking/","text":"Commands \u00b6 # all port usage netstat -pnltu # specific port usage lsof -i :9000 netstat -ltnp | grep -w ':80' Endpoint Info \u00b6 Useful when trying to verify if headers are acting as they're supposed to when building an API curl -is http://google.com HTTP/2 301 location: https://www.google.com/ content-type: text/html; charset=UTF-8 date: Fri, 23 Apr 2021 15:36:48 GMT expires: Sun, 23 May 2021 15:36:48 GMT cache-control: public, max-age=2592000 server: gws content-length: 220 x-xss-protection: 0 x-frame-options: SAMEORIGIN","title":"Networking"},{"location":"pages/networking/#commands","text":"# all port usage netstat -pnltu # specific port usage lsof -i :9000 netstat -ltnp | grep -w ':80'","title":"Commands"},{"location":"pages/networking/#endpoint-info","text":"Useful when trying to verify if headers are acting as they're supposed to when building an API curl -is http://google.com HTTP/2 301 location: https://www.google.com/ content-type: text/html; charset=UTF-8 date: Fri, 23 Apr 2021 15:36:48 GMT expires: Sun, 23 May 2021 15:36:48 GMT cache-control: public, max-age=2592000 server: gws content-length: 220 x-xss-protection: 0 x-frame-options: SAMEORIGIN","title":"Endpoint Info"},{"location":"pages/nginx/","text":"Apache Configs \u00b6 To convert .htaccess configs to nginx configs. Use this site. PHP Config \u00b6 Here's a base nginx config for php. Make sure to change the php version and the <url> . server { listen 80 ; listen [::]:80 ; server_name <url> ; root /var/www/html ; index index.php index.html index.htm index.nginx-debian.html ; location / { try_files $uri $uri/ = 404 ; } location ~ \\.php$ { include snippets/fastcgi-php.conf ; fastcgi_pass unix:/var/run/php/phpx.x-fpm.sock ; } } Transfer www \u00b6 First create an A record from both the root domain and the www subdomain towards the ip. Then in the nginx conf file, add the block below seperately server { listen 80 ; server_name www.example.com ; return 301 $scheme://example.com$request_uri ; }","title":"Nginx"},{"location":"pages/nginx/#apache-configs","text":"To convert .htaccess configs to nginx configs. Use this site.","title":"Apache Configs"},{"location":"pages/nginx/#php-config","text":"Here's a base nginx config for php. Make sure to change the php version and the <url> . server { listen 80 ; listen [::]:80 ; server_name <url> ; root /var/www/html ; index index.php index.html index.htm index.nginx-debian.html ; location / { try_files $uri $uri/ = 404 ; } location ~ \\.php$ { include snippets/fastcgi-php.conf ; fastcgi_pass unix:/var/run/php/phpx.x-fpm.sock ; } }","title":"PHP Config"},{"location":"pages/nginx/#transfer-www","text":"First create an A record from both the root domain and the www subdomain towards the ip. Then in the nginx conf file, add the block below seperately server { listen 80 ; server_name www.example.com ; return 301 $scheme://example.com$request_uri ; }","title":"Transfer www"},{"location":"pages/php/","text":"Version Mayhem \u00b6 Start by deleting every php version sudo apt-get purge php7.* sudo apt-get autoclean sudo apt-get autoremove Then follow a suitable guide and install the correct version. Switching Active Version \u00b6 Enabling and disabling a specific version. For plain php; # disable sudo a2dismod php7.0 # enable sudo a2enmod php7.2 For php-fpm; # disable sudo service phpx.x-fpm stop # enable sudo service phpx.x-fpm start Then rerun web server sudo service apache2 restart sudo service nginx restart Plugins \u00b6 When installing plugins don't just install it by it's name. You must specify the php version as well. For example when trying to install the php-xml plugin. You must run; sudo apt install php-xml This would install the plugin for the most recent version of php. Which may or may not be the version you have running. So, first check the php version you have running using php --version . Then install the package that's relevant to it. # for php7.4 sudo apt install php7.4-xml Testing \u00b6 Create the directory /var/www/php-test and place an index.php file with; <?php phpinfo (); ?> Config Location \u00b6 Usually there's multiple php config files that exist. So you must figure out which file you're using. Then again, you could even be using multiple at the same time. However, if you're running both apache and nginx at the same time. There's a possibility that the two are using different php.ini 's. First create a php-test file. Then serve it with the preferred web server. Apache \u00b6 Create a new conf file at /etc/apache2/sites-available and point it towards the test file. Remember to route the traffic if you're using an nginx reverse proxy to serve apache requests with nginx requests. If so, you'll need to customize the apache config at /etc/nginx as well. Nginx \u00b6 Create a config file at /etc/nginx with the usual php stuff. Then point it towards the test file. ERROR - 413 \u00b6 The main causes for 413 files too large are; The web server limits it PHP limits it Web Server Limitations \u00b6 Apache \u00b6 Incease the LimitRequestBody . It can be used in any virtualhost or location directive. Check here for more info. You need to convert whatever request size you need into bytes. Use this to convert. <Directory \"/var/www/site\" > LimitRequestBody 5242880 </Directory> Afterwords remember to restart apache. sudo service apache2 reload Nginx \u00b6 This is easy. Just edit the nginx config. sudo nano /etc/nginx/nginx.conf Then change this to whatever size you want. client_max_body_size 2M; Afterwords remember to restart nginx. sudo service nginx reload PHP Limitations \u00b6 First figure out which php .ini file is read . In it, find and change the below parameters to the size you require. upload_max_filesize = 100M post_max_size = 100M Afterwords remember to restart the web server and php. sudo service apache2 restart sudo service nginx restart sudo service phpx.x-fpm restart","title":"PHP"},{"location":"pages/php/#version-mayhem","text":"Start by deleting every php version sudo apt-get purge php7.* sudo apt-get autoclean sudo apt-get autoremove Then follow a suitable guide and install the correct version.","title":"Version Mayhem"},{"location":"pages/php/#switching-active-version","text":"Enabling and disabling a specific version. For plain php; # disable sudo a2dismod php7.0 # enable sudo a2enmod php7.2 For php-fpm; # disable sudo service phpx.x-fpm stop # enable sudo service phpx.x-fpm start Then rerun web server sudo service apache2 restart sudo service nginx restart","title":"Switching Active Version"},{"location":"pages/php/#plugins","text":"When installing plugins don't just install it by it's name. You must specify the php version as well. For example when trying to install the php-xml plugin. You must run; sudo apt install php-xml This would install the plugin for the most recent version of php. Which may or may not be the version you have running. So, first check the php version you have running using php --version . Then install the package that's relevant to it. # for php7.4 sudo apt install php7.4-xml","title":"Plugins"},{"location":"pages/php/#testing","text":"Create the directory /var/www/php-test and place an index.php file with; <?php phpinfo (); ?>","title":"Testing"},{"location":"pages/php/#config-location","text":"Usually there's multiple php config files that exist. So you must figure out which file you're using. Then again, you could even be using multiple at the same time. However, if you're running both apache and nginx at the same time. There's a possibility that the two are using different php.ini 's. First create a php-test file. Then serve it with the preferred web server.","title":"Config Location"},{"location":"pages/php/#apache","text":"Create a new conf file at /etc/apache2/sites-available and point it towards the test file. Remember to route the traffic if you're using an nginx reverse proxy to serve apache requests with nginx requests. If so, you'll need to customize the apache config at /etc/nginx as well.","title":"Apache"},{"location":"pages/php/#nginx","text":"Create a config file at /etc/nginx with the usual php stuff. Then point it towards the test file.","title":"Nginx"},{"location":"pages/php/#error-413","text":"The main causes for 413 files too large are; The web server limits it PHP limits it","title":"ERROR - 413"},{"location":"pages/php/#web-server-limitations","text":"","title":"Web Server Limitations"},{"location":"pages/php/#apache_1","text":"Incease the LimitRequestBody . It can be used in any virtualhost or location directive. Check here for more info. You need to convert whatever request size you need into bytes. Use this to convert. <Directory \"/var/www/site\" > LimitRequestBody 5242880 </Directory> Afterwords remember to restart apache. sudo service apache2 reload","title":"Apache"},{"location":"pages/php/#nginx_1","text":"This is easy. Just edit the nginx config. sudo nano /etc/nginx/nginx.conf Then change this to whatever size you want. client_max_body_size 2M; Afterwords remember to restart nginx. sudo service nginx reload","title":"Nginx"},{"location":"pages/php/#php-limitations","text":"First figure out which php .ini file is read . In it, find and change the below parameters to the size you require. upload_max_filesize = 100M post_max_size = 100M Afterwords remember to restart the web server and php. sudo service apache2 restart sudo service nginx restart sudo service phpx.x-fpm restart","title":"PHP Limitations"},{"location":"pages/postfix/","text":"Pre-setup \u00b6 Create mailgun flex account at https://www.mailgun.com . Then make an SMTP user and take down these. username ( name@domain.com / postmaster@domain.com ) password smtp hostname ( smtp.eu.mailgun.org / smtp.us.mailgun.org ) Postfix Setup \u00b6 Firstly install postfix. On the tui that's displayed select internet site and enter your FQDN. sudo apt-get update && sudo apt-get install postfix If you don't get an interactive prompt. Fully remove and reinstall postfix. sudo apt purge postfix && sudo apt-get install postfix Add the regular user to the postfix group to send mails without auth problems usermod -a -G postfix <username> After installation edit postfix config file at /etc/postfix/main.cf . Find suitable settings from the reference 1 mydestination = localhost.domain, localhost relayhost = [<SMTP hostname>]:587 smtp_sasl_auth_enable = yes smtp_sasl_password_maps = static:<postmaster@domain.com>:<password> smtp_sasl_security_options = noanonymous smtp_tls_security_level = may smtpd_tls_security_level = may smtp_tls_note_starttls_offer = yes # domain mapper smtp_generic_maps = hash:/etc/postfix/generic To customize the domain name mails are sent as, a domain mapper must be created for each user. Create a new file /etc/postfix/generic . In it add records for each user. The first part identifies the user in the host server. The second part is what's displayed in the email's from section. username@hostname sender@domain someone@zen noreplay@thelonelylands.com Then to initialize change run sudo postmap /etc/postfix/generic sudo service postfix reload Postfix configs are errorless if the result is none sudo postfix check sudo service postfix reload Further you check runtime logs for errors service postfix status == > active ( exited ) Finally test it using sendmail echo \"Some text\" | sendmail <recipient-email> Troubleshooting \u00b6 If you encounter the warning below when checking config. Just act as if you didn't see it 2 postfix/postfix-script : warning: symlink leaves directory: /etc/postfix/./makedefs.out The 535 Authentication Error usually implies an error in the data we give. May it be a password, a link or the hostname. https://documentation.mailgun.com/en/latest/user_manual.html#smtp-relay \u21a9 https://serverfault.com/questions/1004137/postfix-postfix-script-warning-symlink-leaves-directory-etc-postfix-makedefs \u21a9","title":"Postfix"},{"location":"pages/postfix/#pre-setup","text":"Create mailgun flex account at https://www.mailgun.com . Then make an SMTP user and take down these. username ( name@domain.com / postmaster@domain.com ) password smtp hostname ( smtp.eu.mailgun.org / smtp.us.mailgun.org )","title":"Pre-setup"},{"location":"pages/postfix/#postfix-setup","text":"Firstly install postfix. On the tui that's displayed select internet site and enter your FQDN. sudo apt-get update && sudo apt-get install postfix If you don't get an interactive prompt. Fully remove and reinstall postfix. sudo apt purge postfix && sudo apt-get install postfix Add the regular user to the postfix group to send mails without auth problems usermod -a -G postfix <username> After installation edit postfix config file at /etc/postfix/main.cf . Find suitable settings from the reference 1 mydestination = localhost.domain, localhost relayhost = [<SMTP hostname>]:587 smtp_sasl_auth_enable = yes smtp_sasl_password_maps = static:<postmaster@domain.com>:<password> smtp_sasl_security_options = noanonymous smtp_tls_security_level = may smtpd_tls_security_level = may smtp_tls_note_starttls_offer = yes # domain mapper smtp_generic_maps = hash:/etc/postfix/generic To customize the domain name mails are sent as, a domain mapper must be created for each user. Create a new file /etc/postfix/generic . In it add records for each user. The first part identifies the user in the host server. The second part is what's displayed in the email's from section. username@hostname sender@domain someone@zen noreplay@thelonelylands.com Then to initialize change run sudo postmap /etc/postfix/generic sudo service postfix reload Postfix configs are errorless if the result is none sudo postfix check sudo service postfix reload Further you check runtime logs for errors service postfix status == > active ( exited ) Finally test it using sendmail echo \"Some text\" | sendmail <recipient-email>","title":"Postfix Setup"},{"location":"pages/postfix/#troubleshooting","text":"If you encounter the warning below when checking config. Just act as if you didn't see it 2 postfix/postfix-script : warning: symlink leaves directory: /etc/postfix/./makedefs.out The 535 Authentication Error usually implies an error in the data we give. May it be a password, a link or the hostname. https://documentation.mailgun.com/en/latest/user_manual.html#smtp-relay \u21a9 https://serverfault.com/questions/1004137/postfix-postfix-script-warning-symlink-leaves-directory-etc-postfix-makedefs \u21a9","title":"Troubleshooting"},{"location":"pages/python/","text":"Extract Requirements \u00b6 # install tool python3 - m pip install - U pipreqs # go to script folder pipreqs . List Deduplication \u00b6 >>> some = [ 1 , 2 , 3 , 4 ] >>> filtered = set ( some ) >>> filtered # {1, 2, 3} Zero Padding \u00b6 >>> i = 2 >>> padded = f \"Three { i : 03d } \" >>> padded = ' {foo:03d} ' . format ( foo = i ) >>> padded # Three 002","title":"Python"},{"location":"pages/python/#extract-requirements","text":"# install tool python3 - m pip install - U pipreqs # go to script folder pipreqs .","title":"Extract Requirements"},{"location":"pages/python/#list-deduplication","text":">>> some = [ 1 , 2 , 3 , 4 ] >>> filtered = set ( some ) >>> filtered # {1, 2, 3}","title":"List Deduplication"},{"location":"pages/python/#zero-padding","text":">>> i = 2 >>> padded = f \"Three { i : 03d } \" >>> padded = ' {foo:03d} ' . format ( foo = i ) >>> padded # Three 002","title":"Zero Padding"},{"location":"pages/regex/","text":"Generators \u00b6 Name Link selector here english-regex here Testers \u00b6 Name Link regexr here","title":"RegEx"},{"location":"pages/regex/#generators","text":"Name Link selector here english-regex here","title":"Generators"},{"location":"pages/regex/#testers","text":"Name Link regexr here","title":"Testers"},{"location":"pages/storage/","text":"Storage Usage Commands \u00b6 Syntax Description df -h mount file usage and availability ncdu storage usage visualization Sorted biggest 10 file in the current dir sub-system. du -ah . | sort -n -r | head -n 10 Sorted biggest 10 dirs of one dir below current dir sub-system. du -h . --max-depth = 2 | sort -n -r | head -n 10 Unlinked File Storage Hogging \u00b6 Display pid of resources that processes are holding onto even if the origin is deleted. lsof | grep deleted | awk '{print $2}' Applications using unlinked files can be printed using lsof +L1 . Removing those files using their ids and killing the processes holding them. # Extract the processes lsof | grep deleted | awk '{print $2}' > ids #!/bin/bash input = \"./ids\" while IFS = read -r line do kill -9 \" $line \" done < \" $input \"","title":"Storage"},{"location":"pages/storage/#storage-usage-commands","text":"Syntax Description df -h mount file usage and availability ncdu storage usage visualization Sorted biggest 10 file in the current dir sub-system. du -ah . | sort -n -r | head -n 10 Sorted biggest 10 dirs of one dir below current dir sub-system. du -h . --max-depth = 2 | sort -n -r | head -n 10","title":"Storage Usage Commands"},{"location":"pages/storage/#unlinked-file-storage-hogging","text":"Display pid of resources that processes are holding onto even if the origin is deleted. lsof | grep deleted | awk '{print $2}' Applications using unlinked files can be printed using lsof +L1 . Removing those files using their ids and killing the processes holding them. # Extract the processes lsof | grep deleted | awk '{print $2}' > ids #!/bin/bash input = \"./ids\" while IFS = read -r line do kill -9 \" $line \" done < \" $input \"","title":"Unlinked File Storage Hogging"},{"location":"pages/systemd/","text":"Service Files \u00b6 When you need to auto start or keep something running in the background, a systemd service is the best option. All user created service files should be inside of etc/systemd/system . The name you give to the service file, for example some.service is what you use with the systemctl or service command. For added security, consider creating a system user for each service. Make sure to not reuse an existing one. Systemd expects the full path of the tool you wish to use. Here's a basic systemd service file template. [Unit] Description = Details about the service [Service] User = <user> Group = <group> ExecStart = <command-to-start> WorkingDirectory = /path KillMode = process Restart = on-failure ; restarts if it fails [Install] WantedBy = multi-user.target # reload systemd sudo systemctl daemon-reload # start it sudo systemctl enable <app-service> sudo systemctl start <app-service> # status sudo systemctl status <app-service> # logs journalctl -u <app-service>","title":"Systemd"},{"location":"pages/systemd/#service-files","text":"When you need to auto start or keep something running in the background, a systemd service is the best option. All user created service files should be inside of etc/systemd/system . The name you give to the service file, for example some.service is what you use with the systemctl or service command. For added security, consider creating a system user for each service. Make sure to not reuse an existing one. Systemd expects the full path of the tool you wish to use. Here's a basic systemd service file template. [Unit] Description = Details about the service [Service] User = <user> Group = <group> ExecStart = <command-to-start> WorkingDirectory = /path KillMode = process Restart = on-failure ; restarts if it fails [Install] WantedBy = multi-user.target # reload systemd sudo systemctl daemon-reload # start it sudo systemctl enable <app-service> sudo systemctl start <app-service> # status sudo systemctl status <app-service> # logs journalctl -u <app-service>","title":"Service Files"},{"location":"pages/tor/","text":"Tor Server Setup \u00b6 Install tor and stop it's auto started service. sudo apt install tor && sudo service tor stop Then edit it's config file /etc/tor/torcc SocksPort 0 SocksListerAddress 127.0.0.1 RunAsDaemon 1 DataDirectory /var/lib/tor HiddenServiceDir /var/lib/tor/my_onion_service HiddenServicePort 80 127.0.0.1 : 8921 After configurations start tor. service tor start Info \u00b6 The above automatically creates a hostname (onion url) with it's public and private key pair in the directory specified with the option HiddenServiceDir inside torcc . Next create an nginx config for the site with the ServerName option set to the generated hostname Troubleshooting \u00b6 Nginx bucket size needs to be increased. The length of a tor address overshoots default config limitations https://www.bentasker.co.uk/documentation/linux/307-building-a-tor-hidden-service-from-scratch-part-1 \u21a9 https://2019.www.torproject.org/docs/tor-onion-service \u21a9 https://github.com/alecmuffett/the-onion-diaries/blob/master/basic-production-onion-server.md \u21a9","title":"Tor"},{"location":"pages/tor/#tor-server-setup","text":"Install tor and stop it's auto started service. sudo apt install tor && sudo service tor stop Then edit it's config file /etc/tor/torcc SocksPort 0 SocksListerAddress 127.0.0.1 RunAsDaemon 1 DataDirectory /var/lib/tor HiddenServiceDir /var/lib/tor/my_onion_service HiddenServicePort 80 127.0.0.1 : 8921 After configurations start tor. service tor start","title":"Tor Server Setup"},{"location":"pages/tor/#info","text":"The above automatically creates a hostname (onion url) with it's public and private key pair in the directory specified with the option HiddenServiceDir inside torcc . Next create an nginx config for the site with the ServerName option set to the generated hostname","title":"Info"},{"location":"pages/tor/#troubleshooting","text":"Nginx bucket size needs to be increased. The length of a tor address overshoots default config limitations https://www.bentasker.co.uk/documentation/linux/307-building-a-tor-hidden-service-from-scratch-part-1 \u21a9 https://2019.www.torproject.org/docs/tor-onion-service \u21a9 https://github.com/alecmuffett/the-onion-diaries/blob/master/basic-production-onion-server.md \u21a9","title":"Troubleshooting"},{"location":"pages/ufw/","text":"Applications \u00b6 Put the apps at /etc/ufw/applications.d/ [appname] title = 1-liner here description = a longer line here ports = 1,2,3,4,5,6,7,8,9,10,30/tcp|50/udp|53 [SMTP Ports] title = Ports for mail client description = Most possibly this would work. I guess ports = 25,465,587,110,995,143,993/tcp OpenSSH - 7777 Nginx - 80, 443 SMTP Ports - 587 Default rules \u00b6 ufw default deny incoming ufw default allow outgoing Commands \u00b6 Syntax Description ufw allow \"SMTP Ports\" allowing an app ufw delete [num] deleting a record","title":"UFW"},{"location":"pages/ufw/#applications","text":"Put the apps at /etc/ufw/applications.d/ [appname] title = 1-liner here description = a longer line here ports = 1,2,3,4,5,6,7,8,9,10,30/tcp|50/udp|53 [SMTP Ports] title = Ports for mail client description = Most possibly this would work. I guess ports = 25,465,587,110,995,143,993/tcp OpenSSH - 7777 Nginx - 80, 443 SMTP Ports - 587","title":"Applications"},{"location":"pages/ufw/#default-rules","text":"ufw default deny incoming ufw default allow outgoing","title":"Default rules"},{"location":"pages/ufw/#commands","text":"Syntax Description ufw allow \"SMTP Ports\" allowing an app ufw delete [num] deleting a record","title":"Commands"},{"location":"pages/veracrypt/","text":"Commands \u00b6 Syntax Description veracrypt -t -l view mounted volumes veracrypt -t -d <path> unmount all (if no path given) Troubleshooting \u00b6 Go to reference if these occur 1 lsof : no pwd entry for UID 201 x forever mount gives device-mapper : create ioctl failed https://askubuntu.com/questions/429612/device-mapper-remove-ioctl-on-luks-xxxx-failed-device-or-resource-busy \u21a9","title":"Veracrypt"},{"location":"pages/veracrypt/#commands","text":"Syntax Description veracrypt -t -l view mounted volumes veracrypt -t -d <path> unmount all (if no path given)","title":"Commands"},{"location":"pages/veracrypt/#troubleshooting","text":"Go to reference if these occur 1 lsof : no pwd entry for UID 201 x forever mount gives device-mapper : create ioctl failed https://askubuntu.com/questions/429612/device-mapper-remove-ioctl-on-luks-xxxx-failed-device-or-resource-busy \u21a9","title":"Troubleshooting"},{"location":"pages/webhooks/","text":"Setup \u00b6 Install the webhook package sudo apt install webhook Create a system user and group to handle webhook instance services. Check out how here . Then go ahead and create a <hookname>.json file. Check out the official docs for more info. Testing \u00b6 When testing run this command to pop a hook instance for the hook.json config. The hotreload flag watches for config file changes and automatically reloads the hook instance. webhook -hooks 'hook.json' -hotreload -verbose The above will start up on the default port 9000 . The hook-name is what's specified in the id field of the json config file. http://localhost:9000/hooks/hook-name Connections \u00b6 Github \u00b6 Check out how here Instance Service \u00b6 Remember, webhook doesn't have a command to create background services. So, you must either; Create a specific systemd service for each hook instance Paste hooks inside /etc/webhook.conf and use the existing webhook service Then route all traffic from the port through an Nginx reverse proxy using an SSL cert provided by certbot and your done. Existing Service \u00b6 Using the default webhook service config to run hook instances. If /etc/webhook.conf doesn't exist, just create a new one. The service file named webhook.service should exist at /etc/systemd/system by default. If not go to the next topic and manually create one. # paste the hooks in here sudo nano /etc/webhook.conf # start it sudo systemctl enable webhook sudo systemctl start webhook Systemd Service \u00b6 Using a systemd service to run a hook instance. Give it a name like webhook-one.service and put it inside of /etc/systemd/system . Make sure to intialize and reload the service and systemd. Creating a seperate group and system user is highly recommended. [Unit] Description = webhook-one [Service] User = webhook Group = webhook ExecStart = webhook -hooks=/path/hook.json -hotreload=false -verbose WorkingDirectory = /path KillMode = process Restart = on-failure [Install] WantedBy = multi-user.target","title":"Webhooks"},{"location":"pages/webhooks/#setup","text":"Install the webhook package sudo apt install webhook Create a system user and group to handle webhook instance services. Check out how here . Then go ahead and create a <hookname>.json file. Check out the official docs for more info.","title":"Setup"},{"location":"pages/webhooks/#testing","text":"When testing run this command to pop a hook instance for the hook.json config. The hotreload flag watches for config file changes and automatically reloads the hook instance. webhook -hooks 'hook.json' -hotreload -verbose The above will start up on the default port 9000 . The hook-name is what's specified in the id field of the json config file. http://localhost:9000/hooks/hook-name","title":"Testing"},{"location":"pages/webhooks/#connections","text":"","title":"Connections"},{"location":"pages/webhooks/#github","text":"Check out how here","title":"Github"},{"location":"pages/webhooks/#instance-service","text":"Remember, webhook doesn't have a command to create background services. So, you must either; Create a specific systemd service for each hook instance Paste hooks inside /etc/webhook.conf and use the existing webhook service Then route all traffic from the port through an Nginx reverse proxy using an SSL cert provided by certbot and your done.","title":"Instance Service"},{"location":"pages/webhooks/#existing-service","text":"Using the default webhook service config to run hook instances. If /etc/webhook.conf doesn't exist, just create a new one. The service file named webhook.service should exist at /etc/systemd/system by default. If not go to the next topic and manually create one. # paste the hooks in here sudo nano /etc/webhook.conf # start it sudo systemctl enable webhook sudo systemctl start webhook","title":"Existing Service"},{"location":"pages/webhooks/#systemd-service","text":"Using a systemd service to run a hook instance. Give it a name like webhook-one.service and put it inside of /etc/systemd/system . Make sure to intialize and reload the service and systemd. Creating a seperate group and system user is highly recommended. [Unit] Description = webhook-one [Service] User = webhook Group = webhook ExecStart = webhook -hooks=/path/hook.json -hotreload=false -verbose WorkingDirectory = /path KillMode = process Restart = on-failure [Install] WantedBy = multi-user.target","title":"Systemd Service"}]}